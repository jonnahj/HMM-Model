{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import numpy as np\n",
    "import copy\n",
    "import re\n",
    "import sys\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = sys.argv[1]\n",
    "# fp = open(filename,\"r\", encoding='utf8')\n",
    "fp = open(\"perceptron-training-data/train-labeled.txt\",\"r\", encoding='utf8')\n",
    "lines = fp.readlines()\n",
    "vocabulary = {}\n",
    "data = {}\n",
    "\n",
    "i = 0\n",
    "for line in lines:\n",
    "    line_list = line.split() \n",
    "    reality = 1 if (line_list[1] == \"True\") else -1\n",
    "    sentiment = 1 if (line_list[2] == \"Pos\") else -1\n",
    "    data[i] = {\"reality\":reality, \"sentiment\":sentiment, \"sentence\": line_list[3:]}\n",
    "    for word in data[i][\"sentence\"]:\n",
    "        copy = word\n",
    "        word = word.replace(\".\",\"\")\n",
    "        word = word.replace(\",\",\"\")\n",
    "        word = word.replace(\"...\",\"\")\n",
    "        word = word.replace(\":\",\"\")\n",
    "        word = word.replace(\";\",\"\")\n",
    "        word = word.replace(\"\\'\",\"\")\n",
    "        word = word.replace(\"\\\"\",\"\")\n",
    "        word = word.replace(\"!\",\"\")\n",
    "        word = word.replace(\"?\",\"\")\n",
    "        word = word.replace(\"(\",\"\")\n",
    "        word = word.replace(\")\",\"\")\n",
    "        word = word.replace(\"~\",\"\")\n",
    "        word = word.replace(\"-\",\"\")\n",
    "        \n",
    "        word = word.lower()\n",
    "        if(word == \"\"):\n",
    "            data[i][\"sentence\"].remove(copy)\n",
    "            continue\n",
    "        \n",
    "        index = data[i][\"sentence\"].index(copy)\n",
    "        data[i][\"sentence\"][index] = word\n",
    "        \n",
    "        if(word in vocabulary):\n",
    "            vocabulary[word] += 1\n",
    "        else:\n",
    "            vocabulary[word] = 1\n",
    "        \n",
    "    i += 1\n",
    "        \n",
    "vocabulary = dict(sorted(vocabulary.items(), key=lambda x: x[1], reverse = True)) #first 34\n",
    "\n",
    "vocab_vector = []\n",
    "for key in vocabulary.keys():\n",
    "    if(vocabulary[key] > 5 and vocabulary[key] < 900):\n",
    "        vocab_vector.append(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_to_vec(line):\n",
    "    blank = [0] * len(vocab_vector)\n",
    "    for i in line:\n",
    "        if(i in vocab_vector):\n",
    "            index = vocab_vector.index(i)\n",
    "            blank[index] += 1\n",
    "            \n",
    "    return blank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in data.keys():\n",
    "    data[i][\"vector\"] = line_to_vec(data[i][\"sentence\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vanilla Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vanilla_model(category):\n",
    "    w = [random.random() for i in range(len(vocab_vector))]\n",
    "    b = random.random()\n",
    "    iterations = 25\n",
    "    for iteration in range(iterations):\n",
    "        for i in data.keys():\n",
    "            a = np.sum(np.multiply(w, data[i][\"vector\"])) + b\n",
    "            \n",
    "            a = 1 if(a>0) else -1\n",
    "            y = data[i][category]\n",
    "            \n",
    "            if(y * a <= 0):\n",
    "                w = np.add(w, np.multiply(data[i][\"vector\"], y))\n",
    "                b += y\n",
    "    return (w, b)\n",
    "\n",
    "reality, b_r = vanilla_model(\"reality\")\n",
    "sentiment, b_s = vanilla_model(\"sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def average_model(category):\n",
    "#     iterations = 25\n",
    "#     w_a = [0] * len(vocab_vector)\n",
    "#     b_a = 0\n",
    "#     w = [random.random() for i in range(len(vocab_vector))]\n",
    "#     b = random.random()\n",
    "#     for iteration in range(iterations):\n",
    "#         for i in data.keys():\n",
    "#             a = np.sum(np.multiply(w, data[i][\"vector\"]))\n",
    "            \n",
    "#             a = 1 if(a>0) else -1\n",
    "#             y = data[i][category]\n",
    "            \n",
    "#             if(y * a < 0):\n",
    "#                 w = np.add(w, np.multiply(data[i][\"vector\"], y))\n",
    "#                 b += y\n",
    "                \n",
    "#         w_a = np.add(w_a,w)\n",
    "#         b_a += b\n",
    "#     return (np.divide(w_a, iterations) , b_a/iteration)\n",
    "\n",
    "# reality_avg, b_r_a = average_model(\"reality\")\n",
    "# sentiment_avg, b_s_a = average_model(\"sentiment\")\n",
    "# print(reality_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-16.53772901  -1.1398463    2.05810482 ...   2.89067187   5.20975627\n",
      "   3.15233136]\n"
     ]
    }
   ],
   "source": [
    "def average_model(category):\n",
    "    iterations = 25\n",
    "    w_a = [0] * len(vocab_vector)\n",
    "    b_a = 0\n",
    "    w = [random.random() for i in range(len(vocab_vector))]\n",
    "    b = random.random()\n",
    "    for iteration in range(iterations):\n",
    "        for i in data.keys():\n",
    "            a = np.sum(np.multiply(w, data[i][\"vector\"]))\n",
    "            \n",
    "            a = 1 if(a>0) else -1\n",
    "            y = data[i][category]\n",
    "            \n",
    "            if(y * a < 0):\n",
    "                w = np.add(w, np.multiply(data[i][\"vector\"], y))\n",
    "                b += y\n",
    "                \n",
    "                w_a = np.add(w_a, np.multiply(data[i][\"vector\"], y*(iteration+1)))\n",
    "                b_a += b\n",
    "                \n",
    "    return (np.subtract(w, np.divide(w_a, iterations)) , b - (b_a/iteration))\n",
    "\n",
    "reality_avg, b_r_a = average_model(\"reality\")\n",
    "sentiment_avg, b_s_a = average_model(\"sentiment\")\n",
    "print(reality_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla = {\"vocab\": vocab_vector, \"reality\":list(reality),\"bias_r\":b_r, \"sentiment\":list(sentiment), \"bias_s\":b_s}\n",
    "average = {\"vocab\": vocab_vector, \"reality\":list(reality_avg), \"bias_r\":b_r_a, \"sentiment\":list(sentiment_avg), \"bias_s\":b_s_a}\n",
    "with open(\"vanillamodel.txt\",\"w\") as file:\n",
    "    file.write(json.dumps(vanilla)) \n",
    "with open(\"averagedmodel.txt\",\"w\") as file:\n",
    "    file.write(json.dumps(average)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vanila - 0.84154\n",
    "#Averaged - 0.84524"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0EL4s2q Fake Neg\n",
      "\n",
      "0UEraLY Fake Neg\n",
      "\n",
      "0cKBWf6 True Neg\n",
      "\n",
      "0gQlq5g Fake Neg\n",
      "\n",
      "0lsa78x Fake Neg\n",
      "\n",
      "0oy1qqz Fake Pos\n",
      "\n",
      "1Eonp7p Fake Neg\n",
      "\n",
      "1acV0r8 Fake Pos\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_f = \"perceptron-training-data/dev-text.txt\"\n",
    "fp = open(input_f, \"r\", encoding='utf8')\n",
    "f = open(\"percepoutput.txt\", \"w\", encoding='utf8')\n",
    "lines = fp.readlines()\n",
    "for line in lines[:8]:\n",
    "    sentence = line.strip().split()\n",
    "    id = sentence[0]\n",
    "    sentence = sentence[1:]\n",
    "    word_vector = line_to_vec(sentence)\n",
    "    \n",
    "    a = np.multiply(word_vector, reality_avg)\n",
    "    reality_result = \"True\" if np.sum(a)+b_r > 0 else \"Fake\"\n",
    "    \n",
    "    a = np.multiply(word_vector, sentiment_avg)\n",
    "    sentiment_result = \"Pos\" if np.sum(a)+b_s > 0 else \"Neg\"\n",
    "    \n",
    "    print(\"\"+id+\" \"+reality_result+\" \"+sentiment_result+\"\\n\")\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
